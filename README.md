Il codice del file `main` implementa un sistema completo per la classificazione utilizzando l'algoritmo K-Nearest Neighbors (KNN). Il flusso del programma include il caricamento del dataset, la sua elaborazione, l'addestramento del modello e la valutazione delle prestazioni attraverso diverse tecniche di validazione.  

Il programma inizia richiedendo all'utente di inserire il path del file contenente il dataset in uno dei formati supportati, come CSV, JSON, TXT o XLSX. Per determinare il metodo di caricamento appropriato, utilizza la funzione `select_load_strategy()`, che seleziona la strategia corrispondente in base all'estensione del file e lo passa al `DataProcessor`.  

Il `DataProcessor` si occupa della fase di preprocessing dei dati, caricando il dataset con la strategia scelta ed eseguendo operazioni fondamentali per migliorare la qualità dei dati. In questa fase, le righe con target mancanti vengono eliminate, mentre le features con valori NaN vengono riempite con la media della colonna corrispondente. Inoltre, alcune colonne non necessarie vengono rimosse, il target viene separato dalle features e queste ultime vengono normalizzate tra 0 e 1. Dopo il preprocessing, i dati elaborati vengono salvati su file CSV e restituiti come array.  

Successivamente, il programma converte le features e il target in array NumPy e chiede all’utente di specificare il valore di `k` per il classificatore KNN. Una volta inserito un valore valido, viene creato un oggetto `KNNClassifier`, che rappresenta il modello di apprendimento basato sull'algoritmo dei k-nearest neighbors.  

Per valutare le prestazioni del modello, viene utilizzata la classe `ModelEvaluator`, che implementa tre metodi di validazione: Holdout, K-Fold Cross Validation e Stratified Shuffle Split. Nel metodo Holdout, il dataset viene diviso in training e test set secondo la proporzione scelta dall’utente e il modello viene addestrato e testato sui rispettivi insiemi. Nel metodo K-Fold Cross Validation, i dati vengono suddivisi in più sottoinsiemi per garantire una valutazione più affidabile, addestrando il modello su una parte del dataset e testandolo su quella restante in più iterazioni. Nel metodo Stratified Shuffle Split, la suddivisione tra training e test set avviene in modo stratificato, mantenendo la distribuzione delle classi nei diversi insiemi e ripetendo l’operazione più volte per ottenere una valutazione più solida.  

Durante la valutazione, vengono calcolate diverse metriche, tra cui accuratezza, tasso di errore, sensibilità (recall), specificità e media geometrica, particolarmente utili per analizzare le prestazioni del modello, soprattutto nel caso di dataset sbilanciati. La matrice di confusione viene calcolata per ciascuna iterazione e aggregata in una matrice complessiva per fornire un quadro dettagliato delle prestazioni. Al termine della valutazione, i risultati vengono salvati in un file TXT denominato `"evaluation_results.txt"`, e l’utente riceve un riepilogo delle informazioni sulle prestazioni del modello.  
